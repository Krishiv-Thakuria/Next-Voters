{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51815e1a",
   "metadata": {},
   "source": [
    "# Email Service - Send to all consumers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7649ae9d",
   "metadata": {},
   "source": [
    "## Download dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede8ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai bs4 pandas requests python-docx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590926da",
   "metadata": {},
   "source": [
    "## Create Zero Shot prompt\n",
    "This will be used to guide LLM when classifying text into the 3 political concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e43322",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "# Identity\n",
    "You are AI model that classifies text into one of the 3 distinct categories. You will be given text as input. That is what you need to classify into one of the categories. \n",
    "The 3 categories are **Immigration**, **Economy**, **Civil**\n",
    "\n",
    "# Instructions\n",
    "* Do not answer in a sentence at all. \n",
    "* Do not give responses with Markdown formatting, just return a one word answer which corresponds to one of the 3 categories mentioned\n",
    "* Never answer in a sentence. \n",
    "* Respond using EXACTLY one word from the allowed categories.\n",
    "\"\"\"\n",
    "\n",
    "with open('political_text_classifier.txt', 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2c48b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "# Identity\n",
    "You are AI summarizing tool that summarizes political legislation in easy to understand language for the public to better understand the texts.\n",
    "\n",
    "# Instructions\n",
    "* Give CLEAR and EASY TO UNDERSTAND explanation of the legislation \n",
    "* Only give information about the content of the legislation. Information like the author or date published should be ignored.\n",
    "* Never add your own comments or thoughts about the text. \n",
    "* Give OBJECTIVE information about the content.\n",
    "* Respond in markdown format with bullet points for easy reading.\n",
    "\"\"\"\n",
    "\n",
    "with open('political_text_summarizer.txt', 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7290ab",
   "metadata": {},
   "source": [
    "## Load Zero Shot prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4fcad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"political_text_classifier.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    political_text_classifier = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335df5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"political_text_summarizer.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    political_text_summarizer = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4cb0ab",
   "metadata": {},
   "source": [
    "## Define AI functions\n",
    "This uses OpenAI SDK and GPT 4o as base LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fcd487",
   "metadata": {},
   "source": [
    "### Set up OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be23bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv('OPENAI_API_KEY')  # Use environment variable instead\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08997c0d",
   "metadata": {},
   "source": [
    "### Political text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b0bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyText(input_text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": political_text_classifier\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": input_text}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip().split()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8367ae4a",
   "metadata": {},
   "source": [
    "### Summarizer of legislative text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd1fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeText(input_text: str):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": political_text_summarizer},\n",
    "            {\"role\": \"user\", \"content\": input_text}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa7eedf",
   "metadata": {},
   "source": [
    "## Build webscraper to get NYC legislation\n",
    "BeautifulSoup will be used to access HTML of NYC Legistar website. We will save the scraped data in a Pandas dataframe for further processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21968db2",
   "metadata": {},
   "source": [
    "### Scrape council committee meetings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff65b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "request_url = \"https://legistar.council.nyc.gov/Calendar.aspx?Mode=This+Week\"\n",
    "web_html = requests.get(request_url).text\n",
    "soup = BeautifulSoup(web_html, \"html.parser\")\n",
    "table = soup.find('table', id='ctl00_ContentPlaceHolder1_gridCalendar_ctl00')\n",
    "\n",
    "council_meetings = []\n",
    "\n",
    "# Skip the header row which is index 0\n",
    "# Only get the 2 most recent meetings\n",
    "for tr in table.find_all('tr')[1:]:  \n",
    "    cells = tr.find_all('td')\n",
    "\n",
    "    committee = cells[0].get_text(strip=True)\n",
    "    date = cells[1].get_text(strip=True)\n",
    "    meeting_time = cells[3].get_text(strip=True)\n",
    "    \n",
    "    if meeting_time == \"Deferred\":\n",
    "        continue\n",
    "    \n",
    "    # Get the agenda link (from the 7th column)\n",
    "    meeting_detail = cells[6].find('a')\n",
    "    meeting_detail_aspx = meeting_detail['href']    \n",
    "    \n",
    "    if len(council_meetings) < 2:\n",
    "        council_meetings.append({\n",
    "            'Date': date,\n",
    "            'Committee': committee,\n",
    "            'Meeting Details': meeting_detail_aspx\n",
    "        })\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f6833e",
   "metadata": {},
   "source": [
    "### View council meetings in a formatted manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47feafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(council_meetings)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff192dd6",
   "metadata": {},
   "source": [
    "### Scrape Meeting Details + Process through AI\n",
    "- Iterate through each meeting detail and iterate through each \"Introduction\" legislative text\n",
    "- Run the text through the 2 AI helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5faaa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    \"Immigration\": [],\n",
    "    \"Economy\": [],\n",
    "    \"Civil\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f00ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from docx import Document\n",
    "\n",
    "for meeting in council_meetings:\n",
    "    meeting_details_url = f\"https://legistar.council.nyc.gov/{meeting['Meeting Details']}\"\n",
    "    meeting_details_html = requests.get(meeting_details_url).text\n",
    "    soup = BeautifulSoup(meeting_details_html, \"html.parser\")  \n",
    "    table = soup.find('table', id='ctl00_ContentPlaceHolder1_gridMain_ctl00')\n",
    "    legislation_file = []\n",
    "    \n",
    "    for tr in table.find_all('tr')[1:]:  # Skip header row\n",
    "        cells = tr.find_all('td')\n",
    "        file_type = cells[6].get_text(strip=True)\n",
    "        if file_type != \"Introduction\":\n",
    "            continue\n",
    "        \n",
    "        file_locator = cells[0].find('a')['href']\n",
    "        if len(legislation_file) > 2:\n",
    "            break\n",
    "        \n",
    "        legislation_file.append(file_locator)\n",
    "    \n",
    "    for file_locator in legislation_file:\n",
    "        response = requests.get(f\"https://legistar.council.nyc.gov/{file_locator}\").text\n",
    "        soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "        span_body = soup.find('span', id=\"ctl00_ContentPlaceHolder1_lblAttachments2\")\n",
    "        legislation_pdf_link = span_body.find_all('a')[2]['href']\n",
    "        name = soup.find('span', id=\"ctl00_ContentPlaceHolder1_lblName2\").get_text(strip=True)\n",
    "        status = soup.find('span', id=\"ctl00_ContentPlaceHolder1_lblStatus2\").get_text(strip=True)\n",
    "\n",
    "        fetched_document = requests.get(f\"https://legistar.council.nyc.gov/{legislation_pdf_link}\")\n",
    "        doc = Document(BytesIO(fetched_document.content))    \n",
    "        legislation_text = '\\n'.join([para.text for para in doc.paragraphs])\n",
    "\n",
    "        category = classifyText(legislation_text)\n",
    "        summarized_category = summarizeText(legislation_text)\n",
    "\n",
    "        categories[category].append({\n",
    "            \"Name\": name,\n",
    "            \"Status\": status,\n",
    "            \"Summarized\": summarized_category\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605696e6",
   "metadata": {},
   "source": [
    "## Email to subscribers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f11e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement email functionality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
