{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51815e1a",
   "metadata": {},
   "source": [
    "# Email Service - Send to all customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7649ae9d",
   "metadata": {},
   "source": [
    "### Download dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ede8ac4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from bs4) (4.13.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->bs4) (2.8)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.2\n"
     ]
    }
   ],
   "source": [
    "%pip install openai bs4 pandas requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e43322",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a7290ab",
   "metadata": {},
   "source": [
    "### Load Zero Shot prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4fcad5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/prompts/political_text_classifer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/prompts/political_text_classifer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      2\u001b[0m     instructions \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/prompts/political_text_classifer'"
     ]
    }
   ],
   "source": [
    "with open(\"/prompts/political_text_classifer\", \"r\", encoding=\"utf-8\") as file:\n",
    "    instructions = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4cb0ab",
   "metadata": {},
   "source": [
    "### Define function to run the political text classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadf9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def classifyText(input_text: str):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        instructions=instructions,\n",
    "        input=input_text\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa7eedf",
   "metadata": {},
   "source": [
    "### Run webscraper to get NYC legislation\n",
    "Beautifulsoup will be used to access HTML of NYC Legistar website. We will save the scrapped data in a Pandas dataframe for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff65b795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Date   Committee  \\\n",
      "0                         City Council Stated Meeting  11/25/2025   \n",
      "1                Committee on Women and Gender Equity  11/25/2025   \n",
      "2                        Committee on General Welfare  11/25/2025   \n",
      "3                                Committee on Finance  11/25/2025   \n",
      "4                             Committee on Technology  11/25/2025   \n",
      "5   Committee on Mental Health, Disabilities and A...  11/25/2025   \n",
      "6                               Committee on Land Use  11/25/2025   \n",
      "7   Committee on Governmental Operations, State & ...  11/25/2025   \n",
      "8                 Committee on Civil and Human Rights  11/25/2025   \n",
      "9   Subcommittee on Landmarks, Public Sitings and ...  11/25/2025   \n",
      "10              Subcommittee on Zoning and Franchises  11/25/2025   \n",
      "11                                 Committee on Aging  11/25/2025   \n",
      "12       Committee on Rules, Privileges and Elections  11/25/2025   \n",
      "13               Committee on Civil Service and Labor  11/25/2025   \n",
      "14                      Committee on Criminal Justice  11/25/2025   \n",
      "15        Committee on Consumer and Worker Protection  11/25/2025   \n",
      "16                             Committee on Contracts  11/25/2025   \n",
      "17                  Committee on Parks and Recreation  11/24/2025   \n",
      "18                      Committee on Higher Education  11/24/2025   \n",
      "19              Subcommittee on Zoning and Franchises  11/24/2025   \n",
      "20     Committee on Transportation and Infrastructure  11/24/2025   \n",
      "21        Committee on Consumer and Worker Protection  11/24/2025   \n",
      "\n",
      "                                          Agenda Link  \n",
      "0   https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "1   https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "2   https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "3   https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "4   https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "5   https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "6   https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "7   https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "8   https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "9   https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "10  https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "11  https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "12  https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "13  https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "14  https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "15  https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "16  https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "17  https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "18  https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "19  https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "20  https://legistar.council.nyc.gov/View.ashx?M=I...  \n",
      "21  https://legistar.council.nyc.gov/View.ashx?M=I...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "request_url = \"https://legistar.council.nyc.gov/Calendar.aspx?Mode=This+Week\"\n",
    "web_html = requests.get(request_url).text\n",
    "soup = BeautifulSoup(web_html, \"html.parser\")\n",
    "table = soup.find('table', id='ctl00_ContentPlaceHolder1_gridCalendar_ctl00')\n",
    "\n",
    "# --- Parse data rows ---\n",
    "rows = []\n",
    "for tr in table.find_all('tr')[1:]:  \n",
    "    cells = tr.find_all('td')\n",
    "    date = cells[0].get_text(strip=True)\n",
    "    committee = cells[1].get_text(strip=True)\n",
    "        \n",
    "    # Get the agenda link (third column - find <a> within <span>)\n",
    "    span = cells[2].find('span')\n",
    "    agenda_link = span.find('a') if span else None\n",
    "    agenda_url = agenda_link['href'] if agenda_link and agenda_link.has_attr('href') else ''\n",
    "        \n",
    "    # Make sure the URL is absolute\n",
    "    if agenda_url and not agenda_url.startswith('http'):\n",
    "        agenda_url = 'https://legistar.council.nyc.gov/' + agenda_url.lstrip('/')\n",
    "        \n",
    "    rows.append({\n",
    "            'Date': date,\n",
    "            'Committee': committee,\n",
    "            'Agenda Link': agenda_url\n",
    "    })\n",
    "\n",
    "# --- Build DataFrame ---\n",
    "df = pd.DataFrame(rows)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0434a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
